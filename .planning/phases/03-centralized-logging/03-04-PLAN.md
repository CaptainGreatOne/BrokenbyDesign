---
phase: 03-centralized-logging
plan: 04
type: execute
wave: 2
depends_on: ["03-01", "03-02", "03-03"]
files_modified:
  - docker-compose.yml
  - loki/loki-config.yaml
  - alloy/config.alloy
  - grafana/provisioning/datasources/loki.yml
autonomous: true

must_haves:
  truths:
    - "Loki receives and stores logs from all three application services"
    - "Alloy automatically discovers containers and ships logs to Loki"
    - "Learner can search logs across all services from Grafana Explore using Loki datasource"
    - "Logs are labeled by service name, enabling per-service filtering"
    - "Loki retention is set to 72 hours to manage storage"
  artifacts:
    - path: "loki/loki-config.yaml"
      provides: "Loki monolithic mode config with filesystem storage and 72h retention"
      contains: "retention_period"
    - path: "alloy/config.alloy"
      provides: "Alloy config for Docker container log discovery and shipping"
      contains: "discovery.docker"
    - path: "grafana/provisioning/datasources/loki.yml"
      provides: "Grafana Loki datasource provisioning"
      contains: "type: loki"
    - path: "docker-compose.yml"
      provides: "Loki and Alloy service definitions with healthchecks and resource limits"
      contains: "grafana/loki"
  key_links:
    - from: "alloy/config.alloy"
      to: "loki/loki-config.yaml"
      via: "loki.write endpoint URL"
      pattern: "http://loki:3100"
    - from: "grafana/provisioning/datasources/loki.yml"
      to: "loki/loki-config.yaml"
      via: "Grafana datasource URL"
      pattern: "http://loki:3100"
    - from: "docker-compose.yml"
      to: "alloy/config.alloy"
      via: "volume mount for Alloy config"
      pattern: "config.alloy:/etc/alloy/config.alloy"
---

<objective>
Deploy Loki, Alloy, and Grafana Loki datasource for centralized log aggregation.

Purpose: This is the logging infrastructure that collects, stores, and makes searchable all application service logs. Loki stores logs with service-name labels. Alloy discovers Docker containers and ships their stdout to Loki. Grafana gets a second datasource (Loki) alongside existing Prometheus so the learner can search logs in Explore.

Output: Loki config file, Alloy config file, Grafana Loki datasource provisioning, and Docker Compose service definitions for loki and alloy. After this plan, `docker compose up` starts the full logging pipeline.
</objective>

<execution_context>
@/home/user/.claude/get-shit-done/workflows/execute-plan.md
@/home/user/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-centralized-logging/03-RESEARCH.md
@docker-compose.yml
@grafana/provisioning/datasources/prometheus.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Loki and Alloy configuration files</name>
  <files>
    loki/loki-config.yaml
    alloy/config.alloy
  </files>
  <action>
Create configuration files for Loki and Alloy.

**loki/loki-config.yaml** - Monolithic mode with filesystem storage:

```yaml
auth_enabled: false

server:
  http_listen_port: 3100

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2024-01-01
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

limits_config:
  retention_period: 72h
  max_query_lookback: 72h

compactor:
  working_directory: /loki/compactor
  compaction_interval: 10m
  retention_enabled: true
  retention_delete_delay: 2h
  retention_delete_worker_count: 150
```

**alloy/config.alloy** - Docker container log discovery and shipping:

The Alloy config must:
1. Discover all Docker containers via Docker socket
2. Relabel to extract service name from container name (strip leading `/`)
3. Filter to only collect from application services: `web-gateway`, `order-api`, `fulfillment-worker` (not infrastructure containers)
4. Ship logs to Loki at `http://loki:3100/loki/api/v1/push`

Use the research-validated config pattern:

```alloy
// Discover Docker containers
discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"
}

// Extract service name from container name, filter to app services
discovery.relabel "logs" {
  targets = discovery.docker.containers.targets

  // Extract container name without leading slash
  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "service"
  }

  // Only collect logs from application services
  rule {
    source_labels = ["service"]
    regex         = "(web-gateway|order-api|fulfillment-worker)"
    action        = "keep"
  }
}

// Collect logs from Docker containers
loki.source.docker "app_logs" {
  host       = "unix:///var/run/docker.sock"
  targets    = discovery.relabel.logs.output
  forward_to = [loki.write.endpoint.receiver]
}

// Write logs to Loki
loki.write "endpoint" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
  }
}
```

Create the directories `loki/` and `alloy/` at the project root if they don't exist.
  </action>
  <verify>
Verify files exist and contain expected content:
- `loki/loki-config.yaml` contains `retention_period: 72h` and `auth_enabled: false`
- `alloy/config.alloy` contains `discovery.docker` and `loki.write`
- Alloy config filters to only 3 application services
  </verify>
  <done>Loki config with 72h retention and filesystem storage, Alloy config discovering and shipping container logs to Loki</done>
</task>

<task type="auto">
  <name>Task 2: Add Loki and Alloy to Docker Compose and provision Grafana datasource</name>
  <files>
    docker-compose.yml
    grafana/provisioning/datasources/loki.yml
  </files>
  <action>
**docker-compose.yml** - Add two new services (loki and alloy) and one new volume (loki-data).

Add the `loki` service after the `grafana` service in the Observability Services section:

```yaml
  loki:
    image: grafana/loki:3.6.0
    container_name: loki
    restart: unless-stopped
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:3100/ready || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
```

Add the `alloy` service after `loki`:

```yaml
  alloy:
    image: grafana/alloy:latest
    container_name: alloy
    restart: unless-stopped
    volumes:
      - ./alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command:
      - run
      - --server.http.listen-addr=0.0.0.0:12345
      - /etc/alloy/config.alloy
    ports:
      - "12345:12345"
    depends_on:
      loki:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
```

Add `loki-data:` to the `volumes:` section at the bottom.

Update the resource budget comment at the top to reflect new totals:
- Previous: ~6.3GB total
- Add: Loki 512M limit/256M reservation + Alloy 256M limit/128M reservation = 768M new limits
- New total: ~7.1GB total

Update the `grafana` service `depends_on` to also depend on loki being healthy:

```yaml
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
```

**grafana/provisioning/datasources/loki.yml** - Provision Loki as second datasource:

```yaml
apiVersion: 1

datasources:
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    uid: loki
    isDefault: false
    editable: false
    jsonData:
      maxLines: 1000
```

This follows the existing pattern from prometheus.yml. The uid `loki` provides a stable reference for future phases. `isDefault: false` keeps Prometheus as the default datasource.
  </action>
  <verify>
Verify docker-compose.yml contains:
- `grafana/loki:3.6.0` image reference
- `grafana/alloy:latest` image reference
- `loki-data` volume
- Loki healthcheck using `/ready` endpoint
- Alloy depends on loki healthy
- Grafana depends on both prometheus and loki

Verify grafana/provisioning/datasources/loki.yml exists with:
- `type: loki`
- `uid: loki`
- `url: http://loki:3100`

Run: `docker compose config --services` to verify compose file parses correctly (if Docker is available).
  </verify>
  <done>Docker Compose has loki and alloy services with healthchecks, resource limits, and log rotation. Grafana provisions Loki as second datasource alongside Prometheus.</done>
</task>

</tasks>

<verification>
1. `docker compose config --services` lists loki and alloy (compose file valid)
2. loki/loki-config.yaml exists with 72h retention
3. alloy/config.alloy exists with Docker discovery and service filter
4. grafana/provisioning/datasources/loki.yml exists with uid: loki
5. docker-compose.yml resource budget updated in comment
6. Alloy depends on Loki, Grafana depends on Loki
</verification>

<success_criteria>
- Loki configured in monolithic mode with filesystem storage and 72h retention
- Alloy discovers only application containers (web-gateway, order-api, fulfillment-worker)
- Alloy ships logs to Loki at http://loki:3100/loki/api/v1/push
- Grafana provisions Loki datasource (uid: loki) alongside existing Prometheus
- Resource limits: Loki 512M/256M, Alloy 256M/128M
- Docker log rotation configured on both new services
- Healthchecks on both services for dependency ordering
</success_criteria>

<output>
After completion, create `.planning/phases/03-centralized-logging/03-04-SUMMARY.md`
</output>

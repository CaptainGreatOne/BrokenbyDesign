---
phase: 01-foundation-services
plan: 05
type: execute
wave: 3
depends_on: ["01-02", "01-03", "01-04"]
files_modified:
  - traffic-generator/src/server.js
  - traffic-generator/src/traffic.js
  - traffic-generator/src/logger.js
  - traffic-generator/package.json
  - traffic-generator/Dockerfile
  - docker-compose.yml
autonomous: true

must_haves:
  truths:
    - "Traffic generator auto-starts in steady mode producing continuous HTTP requests"
    - "Traffic mode can be switched via HTTP: /mode/steady, /mode/burst, /mode/overload, /mode/pause"
    - "Traffic hits Nginx entry point, flowing through the full service chain"
    - "Docker Compose profiles work: core (default), tracing, kafka, cicd, full"
    - "All containers have resource limits within 12GB total RAM budget"
    - "GET /status returns current traffic mode and request statistics"
  artifacts:
    - path: "traffic-generator/src/server.js"
      provides: "HTTP control server for traffic mode switching"
      contains: "express"
    - path: "traffic-generator/src/traffic.js"
      provides: "Traffic generation engine with mode-based request patterns"
      contains: "setInterval"
    - path: "traffic-generator/package.json"
      provides: "Node.js dependencies"
      contains: "express"
    - path: "traffic-generator/Dockerfile"
      provides: "Container image for traffic generator"
      contains: "FROM node"
    - path: "docker-compose.yml"
      provides: "Updated compose with profiles and resource limits"
      contains: "profiles:"
  key_links:
    - from: "traffic-generator/src/traffic.js"
      to: "http://nginx"
      via: "HTTP requests to Nginx entry point"
      pattern: "http://nginx"
    - from: "traffic-generator/src/server.js"
      to: "traffic-generator/src/traffic.js"
      via: "mode switching function calls"
      pattern: "setMode|switchMode"
    - from: "docker-compose.yml"
      to: "all services"
      via: "profiles and deploy.resources configuration"
      pattern: "profiles:|memory:"
---

<objective>
Build the traffic generator service and finalize Docker Compose with profiles and resource limits. The traffic generator auto-starts with steady-mode HTTP traffic hitting the Nginx entry point, with HTTP endpoints for mode switching (steady/burst/overload/pause). Docker Compose is updated with profiles for optional service groups and resource limits for all containers within the 12GB RAM budget.

Purpose: The traffic generator creates continuous baseline traffic that makes the system observable from the moment it starts. Without traffic, there's nothing to monitor. The profiles and resource limits ensure the system is manageable and runs within hardware constraints. This plan integrates all prior services into a working whole.

Output: Complete traffic-generator/ directory, updated docker-compose.yml with profiles and resource limits
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-services/01-CONTEXT.md
@.planning/phases/01-foundation-services/01-RESEARCH.md
@.planning/phases/01-foundation-services/01-01-SUMMARY.md
@.planning/phases/01-foundation-services/01-02-SUMMARY.md
@.planning/phases/01-foundation-services/01-03-SUMMARY.md
@.planning/phases/01-foundation-services/01-04-SUMMARY.md
@docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create traffic generator service</name>
  <files>
    traffic-generator/src/server.js
    traffic-generator/src/traffic.js
    traffic-generator/src/logger.js
    traffic-generator/package.json
    traffic-generator/Dockerfile
  </files>
  <action>
    Create a controllable HTTP traffic generator that auto-starts in steady mode:

    1. **traffic-generator/package.json**:
       - name: "traffic-generator"
       - version: "1.0.0"
       - main: "src/server.js"
       - scripts: { "start": "node src/server.js" }
       - dependencies: express ^4.18.0, axios ^1.6.0 (NOT node-fetch -- axios is simpler for HTTP client usage and handles errors better)

    2. **traffic-generator/src/logger.js** - Structured JSON logging (same pattern as web-gateway):
       - Export log(level, message, metadata) function
       - Service name: "traffic-generator"
       - Fields: timestamp, level, service, message, spread metadata

    3. **traffic-generator/src/traffic.js** - Traffic generation engine:
       - Export an object/class with methods: start(), stop(), setMode(modeName), getStatus()
       - Traffic modes configuration:
         - `steady`: 2 requests/second, indefinite (baseline load for observability)
         - `burst`: 20 requests/second, indefinite until mode change
         - `overload`: 100 requests/second, indefinite until mode change
         - `pause`: 0 requests/second (stops all traffic)
       - Request generation:
         - Target URL from TARGET_URL env var (default: "http://nginx")
         - Mix of request types per cycle:
           - 60% POST /orders (create order with random product_id 1-10, quantity 1-5)
           - 25% GET /orders (list recent orders)
           - 15% GET /orders/:id (get specific order, ID from recent creates)
         - Track last N created order IDs for GET requests (ring buffer of ~50)
       - Implementation:
         - Use setInterval for request scheduling
         - Distribute requests evenly across the interval (e.g., 2 RPS = 1 request every 500ms)
         - Track statistics: total_requests, successful, failed, current_rps, by_endpoint counts
         - Log mode changes and periodic stats (every 30 seconds)
         - Handle HTTP errors gracefully (log but don't crash)
         - Add randomization to avoid perfectly uniform traffic (add jitter of +/- 20% to interval)

    4. **traffic-generator/src/server.js** - HTTP control server:
       - Express app on port 8089 (from PORT env var, default 8089)
       - Endpoints:
         - `POST /mode/steady` - Switch to steady mode, return { mode: "steady", rps: 2 }
         - `POST /mode/burst` - Switch to burst mode, return { mode: "burst", rps: 20 }
         - `POST /mode/overload` - Switch to overload mode, return { mode: "overload", rps: 100 }
         - `POST /mode/pause` - Pause all traffic, return { mode: "pause", rps: 0 }
         - `GET /status` - Return { mode, rps, stats: { total, successful, failed, by_endpoint } }
         - `GET /health` - Return { status: "healthy", service: "traffic-generator" }
       - On startup:
         - Wait 10 seconds before starting traffic (let services initialize)
         - Auto-start in steady mode
         - Log "Traffic generator started in steady mode"

    5. **traffic-generator/Dockerfile**:
       - FROM node:20-alpine
       - WORKDIR /app
       - COPY package.json package-lock.json* ./
       - RUN npm install --production
       - COPY src/ /app/src/
       - EXPOSE 8089
       - CMD ["node", "src/server.js"]
  </action>
  <verify>
    - traffic.js defines all 4 modes (steady, burst, overload, pause)
    - traffic.js generates mixed request types (POST, GET list, GET by ID)
    - server.js exposes mode switching endpoints at /mode/{name}
    - server.js exposes /status endpoint with traffic statistics
    - Auto-start in steady mode on startup (with delay)
    - Docker build succeeds: `docker build -t traffic-gen-test traffic-generator/`
  </verify>
  <done>
    Traffic generator auto-starts in steady mode (2 RPS) after 10-second delay. Generates mixed traffic (60% create, 25% list, 15% get-by-id) hitting Nginx entry point. Mode switching via HTTP endpoints. Statistics tracking for monitoring. Dockerfile builds successfully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update Docker Compose with profiles and resource limits</name>
  <files>
    docker-compose.yml
  </files>
  <action>
    Update the docker-compose.yml created in Plan 01 to add Docker Compose profiles and resource limits for all containers.

    **Read the current docker-compose.yml first**, then make these additions:

    1. **Profiles** - Add profile annotations to prepare for future phases:
       - Core services (NO profiles -- always start): postgres, redis, nginx, web-gateway, order-api, fulfillment-worker, traffic-generator
       - Future tracing services (profiles: [tracing, full]): placeholder comments only -- actual services added in Phase 5
       - Future kafka services (profiles: [kafka, full]): placeholder comments only -- actual services added in Phase 7
       - Future cicd services (profiles: [cicd, full]): placeholder comments only -- actual services added in Phase 8
       - Add a comment block at the bottom of the file documenting available profiles:
         ```
         # Profiles:
         #   (default)  - Core services only (3 microservices + postgres + redis + nginx + traffic-gen)
         #   tracing    - Core + distributed tracing (Jaeger, OTel Collector) [Phase 5]
         #   kafka      - Core + event streaming (Kafka, Kafka UI) [Phase 7]
         #   cicd       - Core + CI/CD pipeline (Gitea, Drone) [Phase 8]
         #   full       - All services
         ```

    2. **Resource limits** - Add deploy.resources to EVERY service:
       Budget allocation within 12GB total:
       - postgres: limits 2G memory, 2.0 cpus; reservations 1G, 1.0 cpus
       - redis: limits 512M memory, 1.0 cpus; reservations 256M, 0.5 cpus
       - nginx: limits 128M memory, 0.5 cpus; reservations 64M, 0.25 cpus
       - web-gateway: limits 512M memory, 1.0 cpus; reservations 256M, 0.5 cpus
       - order-api: limits 1G memory, 1.0 cpus; reservations 512M, 0.5 cpus
       - fulfillment-worker: limits 512M memory, 1.0 cpus; reservations 256M, 0.5 cpus
       - traffic-generator: limits 256M memory, 0.5 cpus; reservations 128M, 0.25 cpus

       Total limits: 2G + 512M + 128M + 512M + 1G + 512M + 256M = ~4.9GB (well within 12GB, leaving ~7GB for future profile services)

       Add a comment at the top: `# Resource budget: ~5GB core services, ~7GB reserved for profile services`

    3. **Ensure all build contexts are correct**:
       - Services needing repo-root context (shared proto/): order-api, web-gateway
         Use: `build: { context: ., dockerfile: services/{name}/Dockerfile }`
       - Services with self-contained context: fulfillment-worker, traffic-generator
         Use: `build: ./services/fulfillment-worker` or `build: ./traffic-generator`

    4. **Add restart policy** to all services:
       - `restart: unless-stopped` for all services
       - This ensures services restart on failure but not after `docker compose stop`

    5. **Add logging configuration** to all services (prepare for Phase 3 log collection):
       ```yaml
       logging:
         driver: json-file
         options:
           max-size: "10m"
           max-file: "3"
       ```
       This prevents disk exhaustion from log accumulation.
  </action>
  <verify>
    - `docker compose config` validates the updated compose file
    - All 7 services have deploy.resources.limits defined
    - All 7 services have restart: unless-stopped
    - All 7 services have logging driver configuration
    - Profile comment block exists at bottom of file
    - Build contexts are correct (repo root for proto-dependent services, local for others)
    - Total memory limits sum to approximately 5GB
  </verify>
  <done>
    Docker Compose updated with resource limits for all 7 services (total ~5GB of 12GB budget). Profile placeholder comments document future expansion. All services use json-file logging with rotation (10m max, 3 files). Restart policy ensures resilience. Build contexts correctly configured for proto sharing.
  </done>
</task>

</tasks>

<verification>
- Traffic generator Docker image builds successfully
- docker compose config passes without errors
- All services have resource limits defined
- All services have logging configuration
- Traffic generator defines all 4 modes (steady, burst, overload, pause)
- Traffic generator auto-starts in steady mode
- Mode switching endpoints respond correctly
</verification>

<success_criteria>
- Complete traffic-generator/ directory with control server and traffic engine
- Traffic auto-starts in steady mode (2 RPS) targeting Nginx
- Mode switching via POST /mode/{steady,burst,overload,pause}
- Statistics available via GET /status
- docker-compose.yml has resource limits for all 7 services (~5GB total)
- docker-compose.yml has profile placeholder comments for future phases
- docker-compose.yml has logging rotation and restart policies
- `docker compose config` validates successfully
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-services/01-05-SUMMARY.md`
</output>
